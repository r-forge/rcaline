% \VignetteIndexEntry{Using Rcaline: An Overview} 
% \VignetteKeywords{Rcaline,CALINE,CALINE3}
% \VignetteDepends{MBA}
% \VignettePackage{Rcaline}

\documentclass[a4paper]{article}

\title{Using Rcaline: An Illustrated Example}
\author{David Holstius}
\bibliographystyle{plain}

\usepackage[pdftex]{graphicx}
\usepackage{hyperref}
\usepackage{subfig}

\begin{document}

\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=1em} \DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=1em} \DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=1em} \fvset{listparameters={\setlength{\topsep}{0pt}}} \renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}}

\setkeys{Gin}{width=0.95\textwidth}

<<echo=false>>=
options(width=60, continue=" ")
options(SweaveHooks=list(fig=function() par(mar=c(5.1, 4.1, 1.1, 2.1))))
@

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\Rvar}[1]{\texttt{#1}}
\newcommand{\Rfunc}[1]{\texttt{#1}}
\newcommand{\pkg}[1]{\texttt{#1}}

<<echo=FALSE>>= 
options(
	width=60, 
	continue=" ", 
	SweaveHooks=list(fig=function() par(mar=c(3, 1, 1, 1)+0.1))
	)
@

\SweaveOpts{width=7,height=5}


\maketitle

\section{Introduction}

Here we apply \pkg{Rcaline} to San Francisco data provided by the Bay Area Air Quality Management District (BAAQMD). This example illustrates the basic steps of constructing, running, and visualizing a model with Rcaline.

\section{Model construction}

In this example, the traffic data and the meteorological data have already been imported. If you're unfamiliar with this step, please consult the accompanying vignette, \textit{Importing Data for use with Rcaline}.

There are three objects in the imported data: an \code{ISCFile}, containing hourly meteorological records; a \code{SpatialPolygonsDataFrame}, representing the extent of San Francisco county; and a \code{SpatialLinesDataFrame}, which describes the roadway geometry and the Annual Average Daily Traffic (AADT) counts. 

<<package_data>>=
require(Rcaline)
data(SanFrancisco, package='Rcaline')
ls()
@

\begin{figure}
  \centering
  \subfloat[Meteorology]{\label{fig:meteorology}\includegraphics[width=0.5\textwidth]{SanFrancisco-meteorology}}                
  \subfloat[Highway network]{\label{fig:links}\includegraphics[width=0.5\textwidth]{SanFrancisco-links}}
  \caption{San Francisco data included with the \pkg{Rcaline} package.}
  \label{fig:data}
\end{figure}

\subsection{Meteorology}

The conventional way to supply hourly meteorological data is to use an ``ISC-ready'' meteorology file containing records of wind speed, wind bearing, atmospheric stability, and mixing height. We need only specify whether to use urban or rural mixing heights, as follows: 

<<meteorology,fig=TRUE,include=FALSE>>=
met <- Meteorology(met_5801.isc, use='urban')
show(ggplot(met))
@

The hourly resolution ensures that we can adequately model the seasonal and diurnal variability. Figure~\ref{fig:meteorology} illustrates the joint distribution of wind speed and wind bearing; the wind here is predominantly coming from the south-west.

\subsection{Roadways and traffic}

Importing shapefiles (with a package like \pkg{maptools} or \pkg{rgdal}) is usually the easiest way to get GIS data into R. Figure~\ref{fig:links} shows the San Franciso highway network. This network is composed of multiple \textit{polylines}, each of which is composed of one or more segments or \textit{links}. 

Each polyline in \code{STRte\_BAAQMD\_v2.shp} has an associated attribute, \code{TRVol2009}, that represents the Annual Average Daily Traffic (AADT) volume on that stretch of highway. In order to convert the traffic volume to vehicles per hour, we need to divide the AADT by 24. We also need to specify the road width (in meters). If we had link-level data on the number of lanes, we could use that to impute widths instead of supplying a single value.

\subsection{Emission factors}

We also need to supply emission factors. The units for an emission factor should be \textit{grams per vehicle per mile}. Emission factors can vary by link, just like traffic volume or road width. Inclined stretches of road, for example, might merit a higher emission factor. 

For the sake of this example, we'll use a constant ``unit emission factor'' of 1.0 across the entire highway network. In California, emission factors for specific pollutants can be obtained from models like EMFAC \cite{carb2005estimated,carb2006emfac,emfac2007motor}.

<<links,fig=TRUE,include=FALSE>>=
lnk <- FreeFlowLinks(STRte_BAAQMD_v2.shp,
	vehiclesPerHour = TRVol2009 / 24,
	emissionFactor = 1.0,
	width = 30.0)
plot(SF_county.shp, col="light gray", border=NA)
lines(lnk, lwd=2)
@

The emission rate calculated by CALINE3 for any given link (in grams per mile per hour) is exactly equal to that link's emission factor multiplied by its traffic volume. Further, the incremental concentration contributed by any given link to a downwind receptor is directly proportional to that link's emission rate. This means that the resulting dispersion surface can be linearly scaled to reflect different emissions scenarios, without needing to run the dispersion step again, as long as the emission factors and/or traffic volumes are scaled uniformly.

\subsection{Receptors}

Receptors are the locations at which the dispersed pollutant concentration will be calculated. CALINE3 is a steady-state Gaussian plume model, rather than a numerical grid-based model. Hence, it is up to us to determine the exact nature of the receptor locations. We can essentially do one of two things: (1) generate a set of receptor locations algorithmically; or (2) supply a predefined set of locations.

\begin{figure}
  \centering
  \subfloat[Grid-based]{\label{fig:grid}\includegraphics[width=0.5\textwidth]{SanFrancisco-grid}}                
  \subfloat[Distance-based]{\label{fig:rings}\includegraphics[width=0.5\textwidth]{SanFrancisco-rings}}
  \caption{Receptor locations sampled using two different methods.}
  \label{fig:data}
\end{figure}

\subsubsection{Constructing a receptor grid algorithmically}

Given that modelers often use a regular Cartesian grid (Figure~\ref{fig:grid}), here we show how to generate such a grid. Because we do not expect significant concentrations beyond 1 km, we restrict the grid to locations within 1 km of the highway centerlines.\footnote{To see the code, which relies on \pkg{rgeos}, just type \code{ReceptorGrid} and hit Enter.} 

<<grid,fig=TRUE,include=FALSE>>=
rcp <- ReceptorGrid(lnk, resolution=250, maxDistance=1e3)
plot(SF_county.shp, col="light gray", border=NA)
lines(lnk)
points(rcp, pch='+', cex=0.5)
@

Relying on a Cartesian grid can induce artificial ``hot spots'' where the grid just happens to fall closer to the road. A different approach (Figure~\ref{fig:rings}) is to create receptors at specific distances from the road network. This approach also allows receptors to be packed more densely close to the roadway, and concentrates our modeling efforts (e.g., CPU time) on the more interesting parts of the dispersion field. 

<<rings,fig=TRUE,include=FALSE>>=
rcp <- ReceptorRings(lnk, distances=c(100, 250, 500, 1000))
plot(SF_county.shp, col="light gray", border=NA)
lines(lnk)
points(rcp, pch='+', cex=0.5)
@

If you were interested in estimating aggregate exposures at a population level, you could also construct an irregular grid by sampling locations from predefined regions, like ZIP codes or census tracts.

\subsubsection{Supplying a set of receptors instead of a grid}

Receptor locations need not be constructed algorithmically. For example, you might want to compute predicted concentrations at a set of geocoded street addresses. As long as you have these in a format that you can import into R, you can supply them instead. Just replace the \code{rcp} variable in the code that follows with your \code{SpatialPointsDataFrame} or \code{SpatialPoints} object containing the locations of interest.

\subsection{Other model parameters}

Additional model parameters, including terrain and pollutant characteristics, also need to be specified. For detailed information, consult the CALINE3 User's Guide \cite{benson1979caline3}. Here we supply some reasonable default values:

<<model_setup>>=
ter <- Terrain(surfaceRoughness=80.0)
CO <- Pollutant("Carbon monoxide", 
	molecularWeight = 28.0, 
	settlingVelocity = 0.0)
@

\pagebreak
\section{Predicting concentrations}

The CALINE3 algorithm is CPU-intensive. If you're using R on a console (not, say, the Mac R.app GUI), \pkg{Rcaline} will automatically attempt to use the \pkg{foreach} package to do the computations in parallel, using however many cores you have. The speedup should be nearly linear in the number of cores.\footnote{You can also configure the \code{foreach} package to distribute computation across multiple host machines, although that is outside the scope of this example.}

\subsection{Running the model}

We use the \code{predict} method to actually run the model. Since the model will actually be run once for every meteorological condition we supply (N=\Sexpr{nrow(met)}), it can be quickest to use only a small sample for the first pass. Here we use 1\% of the meteorology, sampled at random:

<<run_model,eval=FALSE>>=
mod <- Caline3Model(lnk, sample.rows(met, p=0.01), rcp, ter, CO)
pred <- predict(mod)
@

<<load_or_compute_predicted,echo=FALSE>>=
if(file.exists('SanFrancisco.Rda')) {
	load('SanFrancisco.Rda')
} else {
	mod <- Caline3Model(lnk, sample.rows(met, p=0.01), rcp, ter, CO)
	pred <- predict(mod)
	save(mod, pred, file='SanFrancisco.Rda')
}
@

The result of running the model is an $M \times N$ array, where $M$ is the number of meteorological conditions and $N$ is the number of receptors. Each cell indicates the concentration, in $g/m^3$, at that receptor during those conditions.

\subsection{Computing summary statistics}

By computing summary statistics such as the mean or maximum, we can  treat the result as a sample from a theoretical annual distribution, and estimate its properties. The \code{aggregate} function computes several statistics by default. Multiplying by $1.0 \times 10^3$ converts the results to $mg/m^3$, and casting the result to a \code{SpatialPointsDataFrame} re-binds the statistics to the receptor locations:

<<aggregate>>=
agg <- aggregate(pred) * 1.0e3
spdat <- as(agg, 'SpatialPointsDataFrame')
spdat[1:3, c('distance', 'mean', 'max')]
@

\pagebreak
\section{Analyzing results}

After aggregation, we can select a statistic of interest and explore the distribution. Here we focus on exploring results graphically, although they could also be tabulated or subjected to statistical tests.

\subsection{Upwind vs. downwind concentrations}

Within the results is a variable, \code{distance}, that contains the distance-to-roadway for each receptor. (Recall that we specified these distances when constructing the receptor grid.) We can use this to divide the receptors into specific classes and explore the distribution of predicted concentrations in each. 

\begin{figure}[hb]
\begin{center}
<<distance_vs_concentration,fig=TRUE>>=
ggplot(aes(x=mean), data=as(spdat, 'data.frame')) +
	geom_histogram(binwidth=5e-2) + 
	stat_density(aes(y=5e-2*..count..), color='red', geom='path') + 
	facet_wrap(~ distance)
@
\end{center}
\caption{Mean predicted concentration, by distance-to-roadway.}
\label{fig:one}
\end{figure}

\pagebreak
\subsection{Mapping}

\begin{figure}[h]
  \centering
  \subfloat[Bubble plot]{\label{fig:bubble}\includegraphics[width=0.5\textwidth]{SanFrancisco-bubble}}                
  \subfloat[Interpolated subregion]{\label{fig:interpolation}\includegraphics[width=0.5\textwidth]{SanFrancisco-interpolation}}
  \caption{Estimated concentrations, with receptors shown as crosshairs.}
  \label{fig:plots}
\end{figure}

The \code{ggplot} package makes it easy to generate maps (Figure~\ref{fig:bubble}). First we define the bounds of the map (San Francisco county); then we add a \code{geom\_point} layer, binding the size, color, and stacking order of the points to our variable of interest. (For more information on using \pkg{ggplot}, consult the \pkg{ggplot} documentation.) We also add a rectangle to highlight a sub-region of interest.

<<bubble,fig=TRUE,include=FALSE,height=5>>=
bounds <- Rectangle(SF_county.shp) 
map <- ggplot(agg, bounds=bounds)
bubbles <- geom_point(aes(x, y, size=mean, color=mean, order=mean))
region <- resize(bounds, 0.25)
box <- geom_rect(aes(xmin=xmin, ymin=ymin, xmax=xmax, ymax=ymax), 
	fill=NA, color='red', data=as(region, 'data.frame'))
show(map + bubbles + box)
@

\subsection{Interpolation}

As an alternative to the bubble plot, it's possible to construct a raster image by interpolating a summary statistic back to a regular grid (Figure~\ref{fig:interpolation}). We can also change the extent of the map, so that we zoom in on our region of interest. 

Here we intersect the region of interest defined above (red box, Figure~\ref{fig:bubble}) with a 1 km buffer constructed around the highways. Then we sample the resulting sub-region with \code{spsample}, such that we obtain a regular grid having 10,000 points:

<<grid_region>>=
buf <- gBuffer(centerlines(lnk), width=1e3)
buf <- gIntersection(buf, as(region, 'SpatialPolygons'))
grd <- spsample(buf, n=1e4, type='regular', offset=c(0.5, 0.5))
coordnames(grd) <- c('x', 'y')
@

After the grid has been constructed, a method for interpolation must be selected. Here, we use multilevel B-splines \cite{lee1997scattered}, as implemented by the \pkg{MBA} package. 

Note that we replace the primary plot data by using the \code{\%+\%} operator. We also use \code{geom\_tile}, instead of \code{geom\_point}, to construct the ``heatmap''.

<<interpolation,fig=TRUE,include=FALSE,png=TRUE,pdf=FALSE,eps=FALSE>>=
require(MBA)
obs <- cbind(coordinates(spdat), z=spdat$mean)
fit <- mba.points(obs, coordinates(grd), verbose=FALSE)
srf <- with(fit, as.data.frame(xyz.est))
map <- ggplot(agg, bounds=region) %+% srf
show(map + geom_tile(aes(x, y, alpha=z), fill='red') + 
	scale_alpha('mg/m3', to=c(0, 1)))
@

<<save_workspace,echo=FALSE>>=
#save.image('SanFrancisco.Rda')
@

\pagebreak
\bibliography{Rcaline}

\end{document}
